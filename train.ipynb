{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install = False\n",
    "if install:\n",
    "    %pip install nengo_dl\n",
    "    %pip install --force-reinstall -v nengo==3.2 \n",
    "    %pip install --force-reinstall -v tensorflow==2.11\n",
    "    !(mkdir datasets; \\\n",
    "    cd datasets; \\\n",
    "    wget https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip; \\\n",
    "    unzip gzip.zip; cd gzip; gunzip emnist-balanced-train-images-idx3-ubyte.gz; \\\n",
    "    gunzip emnist-balanced-train-labels-idx1-ubyte.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import nengo_dl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from string import ascii_uppercase\n",
    "from segmentation import segmentoutletters\n",
    "\n",
    "def read_images(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        _, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_labels(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def read_validation_data(n_steps=30):\n",
    "    labels = {\n",
    "            \"(BARCODE)0003\": \"AT_02001/2\",\n",
    "            \"(BARCODE)0007\": \"AT_02001/6\",\n",
    "            \"(BARCODE)0015\": \"AT_02002/4\",\n",
    "            \"BG_0005\": \"BG_01001/5\",\n",
    "            \"BG_0012\": \"BG_01002/2\",\n",
    "            \"BG_0014\": \"BG_01002/4\",\n",
    "        }\n",
    "\n",
    "    a = list(range(36)) + [1, 1]\n",
    "    b = list(map(str, range(10))) + list(ascii_uppercase) + [\"/\", \"_\"]\n",
    "    convert_classes = dict(zip(b, a))\n",
    "\n",
    "    for i, name in zip(range(6), os.listdir(\"Dane_przyciete\")):\n",
    "        segmentation_output, _ = segmentoutletters(name)\n",
    "        segmentation_labels = np.array([convert_classes[i] for i in labels[name[:-4]]])\n",
    "        validation_images = np.vstack((validation_images, segmentation_output)) if i else segmentation_output\n",
    "        validation_labels = np.vstack((validation_labels, segmentation_labels.reshape((-1, 1)))) if i else segmentation_labels.reshape((-1, 1))\n",
    "    \n",
    "    validation_labels = np.tile(validation_labels[:, :, None], (1, n_steps, 1))\n",
    "    return validation_images, validation_labels\n",
    "\n",
    "def preprocess(images, labels, n_steps=1, portion=1):\n",
    "    # choose only a portion of the samples, delete lowercase letters\n",
    "    indices = []\n",
    "    for i in range(36):\n",
    "      idcs = np.where(labels == i)[0][::portion]\n",
    "      indices += list(idcs)\n",
    "    images = images[indices, ...]\n",
    "    images = np.moveaxis(images, 2, 1)\n",
    "    labels = labels[indices]\n",
    "    # flatten images\n",
    "    images = images.reshape((images.shape[0], -1))\n",
    "    # add time\n",
    "    images = np.tile(images[:, None, :], (1, n_steps, 1))\n",
    "    labels = np.tile(labels[:, None, None], (1, n_steps, 1))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = read_images('datasets/gzip/emnist-balanced-train-images-idx3-ubyte')\n",
    "train_labels = read_labels('datasets/gzip/emnist-balanced-train-labels-idx1-ubyte')\n",
    "\n",
    "n_steps = 30\n",
    "train_images, train_labels = preprocess(train_images, train_labels, 1, 1)\n",
    "validation_images, validation_labels = read_validation_data(30)\n",
    "# stack data to be able to evaluate with minibatch_size\n",
    "validation_images = np.tile(validation_images, (3, 1, 1))\n",
    "validation_labels = np.tile(validation_labels, (3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(train_images[i, 0, :].reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(train_labels[i, 0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(validation_images[i, 0, :].reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(validation_labels[i, 0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import net\n",
    "model, out_p, out_p_filt = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(y_true, y_pred):\n",
    "    return tf.metrics.sparse_categorical_accuracy(y_true[:, -1], y_pred[:, -1])\n",
    "minibatch_size = 180\n",
    "sim = nengo_dl.Simulator(model, minibatch_size=minibatch_size)\n",
    "sim.compile(\n",
    "        optimizer=tf.optimizers.RMSprop(0.001),\n",
    "        loss={out_p: tf.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "        metrics=classification_accuracy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "max_epochs = 30\n",
    "patience = 5\n",
    "history = {'loss' : [], 'val_loss' : [], 'accuracy' : [], \"val_accuracy\" : []}\n",
    "RUN_ID = \"dropout_123456\" # do zmiany przy douczaniu (żeby nienadpisywały się wagi)\n",
    "prams_dir = \"wagi_epoki/\"\n",
    "# sim.load_params(f'wagi_epoki/params_epoch_1_dropout_0')\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch: {epoch}/{max_epochs}\")\n",
    "    stats = sim.fit(train_images, {out_p : train_labels}, epochs=1)\n",
    "    print(\"Validation results:\")\n",
    "    val_stats = sim.evaluate(validation_images, {out_p_filt : validation_labels})\n",
    "    val_loss = val_stats['loss']\n",
    "    if epoch > 100:\n",
    "        if history['val_loss'][-patience] < val_loss:\n",
    "            best_epoch = min(range(epoch-1), key=lambda e: history['val_loss'][e])\n",
    "            print(\"Training stopped due to overfitting\")\n",
    "            print(f\"Best validation_results at epoch {best_epoch}\")\n",
    "            break\n",
    "    sim.save_params(prams_dir + f\"params_epoch_{epoch}_{RUN_ID}\")\n",
    "    history['loss'].append(stats.history['loss'])\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['accuracy'].append(stats.history['out_p_classification_accuracy'])\n",
    "    history['val_accuracy'].append(val_stats['out_p_classification_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], color='red', marker='.')\n",
    "plt.plot(history['val_loss'], color='blue', marker='.')\n",
    "plt.xticks(np.arange(epoch))\n",
    "ax.legend([\"Trainning loss\", \"Validation loss\"])\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.plot(history['accuracy'], color='red', marker='.')\n",
    "plt.plot(history['val_accuracy'], color='blue', marker='.')\n",
    "plt.xticks(np.arange(epoch))\n",
    "ax.legend([\"Trainning accuracy\", \"Validation accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af5390c80ecda3b61b3eea61f71445c8d472d7c5162b748bf56f6e734ec302c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
